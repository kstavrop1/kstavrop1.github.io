---
title: 'Tester-Learners for Halfspaces: Universal Algorithms'
date: '2023-12-12'
draft: false
publishDate: '2024-08-12T19:48:58.371175Z'
authors:
- Aravind Gollakota
- Adam Klivans
- admin
- Arsen Vasilyan
publication_types:
- 'paper-conference'
abstract: 'We give the first tester-learner for halfspaces that succeeds universally over a wide class of structured distributions. Our universal tester-learner runs in fully polynomial time and has the following guarantee: the learner achieves error $O(\mathrm{opt}) + \epsilon$ on any labeled distribution that the tester accepts, and moreover, the tester accepts whenever the marginal is any distribution that satisfies a Poincaré inequality. In contrast to prior work on testable learning, our tester is not tailored to any single target distribution but rather succeeds for an entire target class of distributions. The class of Poincaré distributions includes all strongly log-concave distributions, and, assuming the Kannan–Lóvasz–Simonovits (KLS) conjecture, includes all log-concave distributions. In the special case where the label noise is known to be Massart, our tester-learner achieves error $\mathrm{opt} + \epsilon$ while accepting all log-concave distributions unconditionally (without assuming KLS). Our tests rely on checking hypercontractivity of the unknown distribution using a sum-of-squares (SOS) program, and crucially make use of the fact that Poincaré distributions are certifiably hypercontractive in the SOS framework.'
featured: true
publication: '**NeurIPS 2023** <span style="font-size:15px;"><i class="fa-solid fa-star"></i></span> ***Oral***'
url_pdf: https://proceedings.neurips.cc/paper_files/paper/2023/file/204d9a9a4816a45909010587ffc3204b-Paper-Conference.pdf
links:
- name: URL
  url: https://neurips.cc/virtual/2023/oral/73861
---

