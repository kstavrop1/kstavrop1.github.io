---
title: Smoothed Analysis for Learning Concepts with Low Intrinsic Dimension
date: '2024-06-30'
draft: false
publishDate: '2024-08-12T19:48:58.161640Z'
authors:
- Gautam Chandrasekaran
- Adam Klivans
- Vasilis Kontonis
- Raghu Meka
- admin
publication_types:
- 'paper-conference'
abstract: '  In the well-studied agnostic model of learning, the goal of a learner– given examples from an arbitrary joint distribution on $\mathbb{R}^d \times \{\pm 1\}\$– is to output a hypothesis that is competitive (to within $\epsilon$) of the best fitting concept from some class.  In order to escape strong hardness results for learning even simple concept classes in this model, we introduce a smoothed analysis framework where we require a learner to compete only with the best classifier that is robust to small random Gaussian perturbation. This subtle change allows us to give a wide array of learning results for any concept that (1) depends on a low-dimensional subspace (aka multi-index model) and (2) has a bounded Gaussian surface area.  This class includes functions of halfspaces and (low-dimensional) convex sets, cases that are only known to be learnable in non-smoothed settings with respect to highly structured distributions such as Gaussians. Perhaps surprisingly, our analysis also yields new results for traditional non-smoothed frameworks such as learning with margin.  In particular, we obtain the first algorithm for agnostically learning intersections of $k$-halfspaces in time  $k^{\mathrm{poly}(\frac{\log k} {\epsilon \gamma})}$ where $\gamma$ is the margin parameter.   Before our work, the best-known runtime was exponential in $k$ (Arriaga and Vempala, 1999).'
featured: true
publication: '**COLT 2024** <span style="font-size:15px;"><i class="fa-solid fa-star"></i></span> ***Best Paper***'
# <span style="font-family: Courier New, sans-serif; font-size:18px; font-weight:1000"> &nbsp;(Best paper award)</span>' 
url_pdf: https://proceedings.mlr.press/v247/chandrasekaran24a/chandrasekaran24a.pdf
links:
- name: URL
  url: https://proceedings.mlr.press/v247/chandrasekaran24a.html
---
---

