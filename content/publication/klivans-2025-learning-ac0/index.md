---
title: Learning Constant-Depth Circuits in Malicious Noise Models
date: '2025-06-01'
draft: false
publishDate: '2024-08-12T19:48:58.474619Z'
authors:
- Adam Klivans
- admin
- Arsen Vasilyan
publication_types:
- 'paper-conference'
abstract: "The seminal work of Linial, Mansour, and Nisan gave a quasipolynomial-time algorithm for learning constant-depth circuits (ùñ†ùñ¢0) with respect to the uniform distribution on the hypercube. Extending their algorithm to the setting of malicious noise, where both covariates and labels can be adversarially corrupted, has remained open. Here we achieve such a result, inspired by recent work on learning with distribution shift. Our running time essentially matches their algorithm, which is known to be optimal assuming various cryptographic primitives. Our proof uses a simple outlier-removal method combined with Braverman's theorem for fooling constant-depth circuits. We attain the best possible dependence on the noise rate and succeed in the harshest possible noise model (i.e., contamination or so-called *nasty noise*)."
featured: true
publication: '**COLT 2025**'
url_pdf: https://arxiv.org/pdf/2411.03570
links:
- name: URL
  url: https://arxiv.org/abs/2411.03570
---

