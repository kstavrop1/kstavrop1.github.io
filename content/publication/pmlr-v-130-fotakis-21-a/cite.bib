@inproceedings{pmlr-v130-fotakis21a,
 abstract = { We consider the problem of learning the true ordering of a set of alternatives from largely incomplete and noisy rankings. We introduce a natural generalization of both the Mallows model, a popular model of ranking distributions, and the extensively studied model of ranking from pairwise comparisons. Our selective Mallows model outputs a noisy ranking on any given subset of alternatives, based on an underlying Mallows distribution. Assuming a sequence of subsets where each pair of alternatives appears frequently enough, we obtain strong asymptotically tight upper and lower bounds on the sample complexity of learning the underlying complete central ranking and the (identities and the) ranking of the top k alternatives from selective Mallows rankings. Moreover, building on the work of (Braverman and Mossel, 2009), we show how to efficiently compute the maximum likelihood complete ranking from selective Mallows rankings. },
 author = {Fotakis, Dimitris and Kalavasis, Alkis and Stavropoulos, Konstantinos},
 booktitle = {Proceedings of The 24th International Conference on Artificial Intelligence and Statistics},
 editor = {Banerjee, Arindam and Fukumizu, Kenji},
 pages = {2278--2286},
 pdf = {http://proceedings.mlr.press/v130/fotakis21a/fotakis21a.pdf},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = { Aggregating Incomplete and Noisy Rankings },
 url = {https://proceedings.mlr.press/v130/fotakis21a.html},
 volume = {130},
 year = {2021}
}

