---
title: The Power of Iterative Filtering for Supervised Learning with (Heavy) Contamination
date: '2025-05-26'
draft: false
publishDate: '2024-08-12T19:48:58.474619Z'
authors:
- Adam Klivans
- admin
- Kevin Tian
- Arsen Vasilyan
publication_types:
- 'paper-conference'
abstract: "Inspired by recent work on learning with distribution shift, we give a general outlier removal algorithm called *iterative polynomial filtering* and show a number of striking applications for supervised learning with contamination: (1) We show that any function class that can be approximated by low-degree polynomials with respect to a hypercontractive distribution can be efficiently learned under bounded contamination (also known as *nasty noise*). This is a surprising resolution to a longstanding gap between the complexity of agnostic learning and learning with contamination, as it was widely believed that low-degree approximators only implied tolerance to label noise. (2) For any function class that admits the (stronger) notion of sandwiching approximators, we obtain near-optimal learning guarantees even with respect to heavy additive contamination, where far more than $1/2$ of the training set may be added adversarially. Prior related work held only for regression and in a list-decodable setting. (3) We obtain the first efficient algorithms for tolerant testable learning of functions of halfspaces with respect to any fixed log-concave distribution. Even the non-tolerant case for a single halfspace in this setting had remained open. These results significantly advance our understanding of efficient supervised learning under contamination, a setting that has been much less studied than its unsupervised counterpart."
featured: false
publication: '*Under review*'
url_pdf: https://arxiv.org/pdf/2505.20177
links:
- name: URL
  url: https://arxiv.org/abs/2505.20177
---
